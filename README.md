# ğŸ’¡ LexAyudha: Personalized AI-Driven Rehabilitation for Adolescents with Dyslexia and Dyscalculia (Research BSc Final Year)

ğŸš€ Live Project Database - https://lexayudha-static.vercel.app/

ğŸ’» Frontend - 

ğŸ’» Backend - 


Dyslexia and dyscalculia, the most common learning disabilities, produce a considerably challenging environment for adolescents and lead to frustration, disengagement, and reduced self-esteem. While assistive technologies with influential functionalities exist, they lack real- time personalization for effective and supportive learning. LexAyudha is an AI-powered platform addressing these gaps by integrating proven medical methodologies such as chromatic variation, Touch Math, and multisensory teaching strategies. Advanced AI technologies like Convolutional and Recurrent Neural Networks have been used in LexAyudha to dynamically adjust reading content, visual layouts, and lesson plans in the gamified app based on students' real-time performances to cater for their requirements. Moreover, a novel emotion recognition algorithm even adjusts difficulty levels of activities and voice output with altered audio features to ensure a stress-free learning process and a stimulating environment. Initial findings based on the user performances tests conducted with the dyslexic and dyscalculia adolescents in Sri Lanka, represents significant improvements in reading fluency, comprehension, and motivation, showing that adaptive learning with AI has the potential to revolutionize learning for dyslexic and dyscalculia students. The research identifies the potential of rehabilitation with AI-driven technology as a flexible and scalable solution for personalized education in dyslexia and dyscalculia.

# ğŸ¯ Project Objectives

âœ… Reduce visual stress using Chromatic Variation-Based Teaching Modules

âœ… Improve reading fluency and comprehension via AI-generated adaptive content

âœ… Enhance understanding of spoken language with Personalized Speech Pace Prediction

âœ… Monitor emotional states in real-time through Facial Emotion Recognition

âœ… Strengthen mathematical understanding using a Gamified Multisensory Touch Math Platform


# ğŸ§  Core Features & Innovations

ğŸŒˆ Chromatic Variation Module

Dynamic adjustment of text and background colors based on individual comfort

Built using Chroma.js, following accessibility standards (e.g., WCAG)

Reduces cognitive fatigue and enhances readability for dyslexic learners

ğŸ“š AI-Driven Sentence Simplification

Uses a fine-tuned BERT NLP model to generate adaptive, simplified content

Tailors reading material complexity in real-time based on performance

ğŸ™ï¸ Personalized Speech Pace & TTS

Combines CNN and RNN models to analyze mel spectrograms of speech

Uses Google TTS to deliver audio at individually optimized pace

Improves comprehension and auditory engagement for neurodiverse learners

ğŸ“· Emotion-Aware Adaptive Learning

Utilizes Xception-based CNNs for facial emotion classification (e.g., frustration, engagement)

Learning difficulty adapts in real time based on detected emotions

Generates emotional progress reports for guardians

ğŸ”¢ Multisensory Touch Math for Dyscalculia

Web-based implementation of the Touch Math method

Interactive, gamified number recognition and arithmetic learning

Supports audio-visual-tactile learning through speech recognition and NLP


# ğŸ› ï¸ Technologies Used

Frontend: React.js (hosted on Vercel)

Backend: Node.js, Express.js (hosted on Render with Docker & Kubernetes)

Database: MongoDB Atlas

AI/ML Models:

Emotion Detection: Xception, MTCNN (facial expression detection)

Speech Pace Prediction: Hybrid CNN-RNN (VGG16 + Wav2Vec 2.0)

Sentence Simplification: BERT, SpaCy, NLTK

Other Tools: Google Text-to-Speech, Chroma.js, Librosa, Prometheus, Grafana

# ğŸ§ª Evaluation & Results
Pilot-tested in real-world school environments

Improvements observed in:

Reading accuracy and speed

Speech comprehension

Emotional regulation and engagement

Positive feedback from:

Educators and students

Guardians via emotional reports

# ğŸ§© Challenges Addressed
Lack of real-time, personalized educational tools for neurodiverse learners

Inadequate emotional and visual accommodations in traditional ed-tech

Static and generalized learning content that fails to engage

# ğŸ“ Future Enhancements
Multilingual support for broader accessibility

Integration of physiological emotion data (e.g., heart rate, galvanic response)

Expansion into other learning disorders and age groups

# ğŸ“œ Citation
This project is the final-year dissertation submitted to the Sri Lanka Institute of Information Technology (SLIIT) by:

Umesha Silva

Ishara Madusanka

Thathsara Thalangama

Tharushi Dissanayake








